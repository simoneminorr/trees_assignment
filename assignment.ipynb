{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA8eWQkKL7_I"
      },
      "source": [
        "# Assignment: Trees\n",
        "\n",
        "## Do two questions in total: \"Q1+Q2\" or \"Q1+Q3\"\n",
        "\n",
        "`! git clone https://github.com/ds3001f25/linear_models_assignment.git`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEbuDDrDL7_I"
      },
      "source": [
        "**Q1.** Please answer the following questions in your own words.\n",
        "1. Why is the Gini a good loss function for categorical target variables?\n",
        "A: The Gini is a good loss function for categorial target variables\n",
        "\n",
        "2. Why do trees tend to overfit, and how can this tendency be constrained?\n",
        "A: Trees tend to overfit because they grow too deep which means it is too complex and trained to the noise of the specific training data that new data is hard to process. This tendency can be constrained in a few different ways. One way is to impose a limit on the depth of the tree. By imposing a hard limit on how many levels the tree can have we can set a limit which will make the tree symmetric and this is sign of a bad preditor. Another way to contrain this tendency is force. Creating min samples per leaf will allow for discernment of approach depending on the data. If the data is very distinguished, the tree can go deep or if the data is not useful then it will be shallow. I can also impose a limit on the cases that appear to be \"too pure\" at the ending node. All of these are examples of data regulation because they stop overfitting early.\n",
        "\n",
        "\n",
        "3. True or false, and explain: Trees only really perform well in situations with lots of categorical variables as features/covariates.\n",
        "A: False, Trees do not only really perform well in situations with lots of categorical variables as features/covariates. Trees handle mixed variables well, including both categorical and numerical features.\n",
        "\n",
        "4. Why don't most versions of classification/regression tree concept allow for more than two branches after a split?\n",
        "A: Most versions of classification/regression tree concept do not allow for more than two branches after a split for multiple reasons. For one, every degree of a split can occur via a series of binary splits which makes the simple and efficient. On this same note, trying to split values with multiple features all at once is more difficult than splitting in two which allows for computational efficency.\n",
        "\n",
        "5. What are some heuristic ways you can examine a tree and decide whether it is probably over- or under-fitting?\n",
        "A: Some heuristic ways I can examine a tree and decide whether it is probable over- or under-fitting is examining the depth. If trees are very deep than that is a sign of overfitting due to a complex model that follows the noise of the data too much. This brings me to another way to evaluate, high performance on training data but low accuracy on new data which means generalizing is difficult for the model which is a sign of overfitting as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aosaapr9L7_I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJCvgKRDL7_J"
      },
      "source": [
        "**Q2.** This is a case study about classification and regression trees.\n",
        "\n",
        "1. Load the `Breast Cancer METABRIC.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  We'll use a consistent set of feature/explanatory variables. For numeric variables, we'll include `Tumor Size`, `Lymph nodes examined positive`, `Age at Diagnosis`. For categorical variables, we'll include `Tumor Stage`, `Chemotherapy`, and `Cancer Type Detailed`. One-hot-encode the categorical variables and concatenate them with the numeric variables into a feature/covariate matrix, $X$.\n",
        "\n",
        "3. Let's predict `Overall Survival Status` given the features/covariates $X$. There are 528 missing values, unfortunately: Either drop those rows from your data or add them as a category to predict. Constrain the minimum samples per leaf to 10. Print a dendrogram of the tree. Print a confusion matrix of the algorithm's performance. What is the accuracy?\n",
        "\n",
        "4. For your model in part three, compute three statistics:\n",
        "    - The **true positive rate** or **sensitivity**:\n",
        "        $$\n",
        "        TPR = \\dfrac{TP}{TP+FN}\n",
        "        $$\n",
        "    - The **true negative rate** or **specificity**:\n",
        "        $$\n",
        "        TNR = \\dfrac{TN}{TN+FP}\n",
        "        $$\n",
        "    Does your model tend to perform better with respect to one of these metrics?\n",
        "\n",
        "5. Let's predict `Overall Survival (Months)` given the features/covariates $X$. Use the train/test split to pick the optimal `min_samples_leaf` value that gives the highest $R^2$ on the test set (it's about 110). What is the $R^2$? Plot the test values against the predicted values. How do you feel about this model for clinical purposes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtA8C64iL7_J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IC3hDwL7_J"
      },
      "source": [
        "**Q3.** This is a case study about trees using bond rating data. This is a dataset about bond ratings for different companies, alongside a bunch of business statistics and other data. Companies often have multiple reviews at different dates. We want to predict the bond rating (AAA, AA, A, BBB, BB, B, ..., C, D). Do business fundamentals predict the company's rating?\n",
        "\n",
        "1. Load the `./data/corporate_ratings.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
        "\n",
        "2.  Plot a histogram of the `ratings` variable. It turns out that the gradations of AAA/AA/A and BBB/BB/B and so on make it hard to get good results with trees. Collapse all AAA/AA/A ratings into just A, and similarly for B and C.\n",
        "\n",
        "3. Use all of the variables **except** Rating, Date, Name, Symbol, and Rating Agency Name. To include Sector, make a dummy/one-hot-encoded representation and include it in your features/covariates. Collect the relevant variables into a data matrix $X$.\n",
        "\n",
        "4. Do a train/test split of the data and use a decision tree classifier to predict the bond rating. Including a min_samples_leaf constraint can raise the accuracy and speed up computation time. Print a confusion matrix and the accuracy of your model. How well do you predict the different bond ratings?\n",
        "\n",
        "5. If you include the rating agency as a feature/covariate/predictor variable, do the results change? How do you interpret this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuQ1XfdjL7_J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}